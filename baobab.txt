# build docker image and upload to docker hub (a git push should do this automatically though)

docker build -t ortografix-img .

# install latest docker image on baobab

module purge && module load GCCcore/8.2.0 && module load Singularity/3.4.0-Go-1.12 && PATH=$PATH:/sbin singularity build ortografix:latest.simg docker://akb89/ortografix:latest

# test script 

srun -p debug-EL7 /home/kabbach/ortografix/experiments/transformer.sh

# run script

sbatch --partition=shared-gpu-EL7 --gres=gpu:1 --time=12:00:00 --output=/home/kabbach/transformer.out /home/kabbach/ortografix/experiments/transformer.sh

sbatch \
--partition=shared-gpu-EL7 \
--gres=gpu:1 \
--time=12:00:00 \
--output=/home/kabbach/attention-gru-1024-3l-30e.out \
/home/kabbach/ortografix/experiments/attention.sh

sbatch \
--partition=shared-gpu-EL7 \
--gres=gpu:1 \
--time=12:00:00 \
--output=/home/kabbach/reverse-gru-128-10e.out \
/home/kabbach/ortografix/experiments/reverse.sh

sbatch \
--partition=shared-gpu-EL7 \
--gres=gpu:1 \
--time=12:00:00 \
--output=/home/kabbach/transformer-512-2l-1h-50e.out \
/home/kabbach/ortografix/experiments/transformer.sh

# script content:

#!/bin/sh Don't forget this at the beginning!!

echo "I: full hostname: $(hostname -f)"

module load GCCcore/8.2.0
module load Singularity/3.4.0-Go-1.12

VERSION_CUDA='10.1.243'
module load CUDA/${VERSION_CUDA}

# if you need to know the allocated CUDA device, you can obtain it here:
echo "I: CUDA_VISIBLE_DEVICES: ${CUDA_VISIBLE_DEVICES}"

echo "====="

srun singularity \
    exec \
    --bind $(readlink /home/kabbach/scratch) \
    --nv \
    /home/kabbach/ortografix-img/ortografix:latest.simg \
        python3 /home/kabbach/experiments/transformer.py
